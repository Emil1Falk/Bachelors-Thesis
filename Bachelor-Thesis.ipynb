{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca719f3f-8019-4072-a589-9ce4a8726818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import unicodedata\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import shap\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0155b739-58ba-438a-8612-1c1fa2c57b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/Users/emilfalk/Desktop/X_train.csv')\n",
    "X_test = pd.read_csv('/Users/emilfalk/Desktop/X_test.csv')\n",
    "y_train = pd.read_csv('/Users/emilfalk/Desktop/y_train.csv')\n",
    "y_test = pd.read_csv('/Users/emilfalk/Desktop/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e060f8-a4de-4de8-a734-9c89488cf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean = X_train['FP'].mean()\n",
    "\n",
    "X_train['FP'] = fp_mean\n",
    "X_test['FP'] = fp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8286c6-422c-470b-9c3d-8fc2850e79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names = X_test['Player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4a23e1-5e01-4bd1-89ec-679d0983ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Player']) \n",
    "X_test = X_test.drop(columns=['Player']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1980f1b4-bf6e-41c7-8fdb-6468230fe4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_basketball = X_train.drop(['years_with_team', 'draft_pos', 'all_star', 'num_teams', 'ig_followers', 'resigned', 'Agent'], axis=1)\n",
    "X_test_basketball = X_test.drop(['years_with_team', 'draft_pos', 'all_star', 'num_teams', 'ig_followers', 'resigned', 'Agent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64533cbe-f19d-4a14-a3f5-2cd782e6fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "basketball_scaler = StandardScaler()\n",
    "X_train_basketball_scaled = basketball_scaler.fit_transform(X_train_basketball) \n",
    "X_test_basketball_scaled = basketball_scaler.transform(X_test_basketball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee423f6f-2990-427d-816a-284d84732b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_scaled_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "X_train_basketball_scaled_cnn = X_train_basketball_scaled.reshape(X_train_basketball_scaled.shape[0], X_train_basketball_scaled.shape[1], 1)\n",
    "X_test_basketball_scaled_cnn = X_test_basketball_scaled.reshape(X_test_basketball_scaled.shape[0], X_test_basketball_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190752f-aaa2-4aae-909e-89c3193fb296",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f977585-b478-4bca-b0f7-74808d8309bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8415441.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10152411.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1782621.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11539524.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45780966.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Salary\n",
       "count      354.00\n",
       "mean   8415441.36\n",
       "std   10152411.94\n",
       "min      19186.00\n",
       "25%    1782621.00\n",
       "50%    4000000.00\n",
       "75%   11539524.50\n",
       "max   45780966.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b08d90c4-15f5-47f0-a08c-e6eb75d36fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(y_train, kde=True)\n",
    "plt.title('Distribution of Salaries')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2daccd9a-164d-4ac1-a61b-573aabeba25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=y_train_values)\n",
    "plt.title('Salary Boxplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5a2c41e-40c3-40f3-aca3-fd5620538e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 34\n",
      "Outlier values: [44310840 29925000 28103500 32405817 26758928 30864198 31650600 26984128\n",
      " 33724200 29467800 31579390 31650600 44310840 31579390 39344900 28103500\n",
      " 36016200 28103500 33003936 45780966 39344970 35500000 35328700 30013500\n",
      " 33003936 42018900 39344900 41180544 35344828 31044906 28103500 39344900\n",
      " 29467800 35995950]\n"
     ]
    }
   ],
   "source": [
    "y_train_values = y_train.values.flatten() if isinstance(y_train, pd.DataFrame) else y_train\n",
    "\n",
    "Q1 = np.percentile(y_train_values, 25)\n",
    "Q3 = np.percentile(y_train_values, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = y_train_values[(y_train_values < lower_bound) | (y_train_values > upper_bound)]\n",
    "print(\"Number of outliers:\", len(outliers))\n",
    "print(\"Outlier values:\", outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01e817-744e-4ff8-8476-258aff90ffd8",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1953bea-da6a-41db-89fe-e0c19d76048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "               Model              Feature Set Dataset          MAE     R2\n",
      "0  Linear Regression      Basketball Features    Test 4210336.7310 0.6694\n",
      "1  Linear Regression  Non-Basketball Features    Test 3722742.0626 0.7482\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "mlr = LinearRegression()\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Linear Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "mlr_basketball = evaluate_model(mlr, X_train_basketball_scaled, X_test_basketball_scaled, y_train, y_test, 'Basketball Features')\n",
    "mlr_full = evaluate_model(mlr, X_train_scaled, X_test_scaled, y_train, y_test, 'Non-Basketball Features')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format) \n",
    "\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45341b6-f9e6-4757-b3b1-9eb1eed7ea28",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c59a82d-c6b0-4272-b1c6-004b1d9ba90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge alpha (Basketball Features): 100.0\n",
      "Best Ridge alpha (Non-Basketball Features): 100.0\n",
      "\n",
      "Ridge Regression Results:\n",
      "              Model              Feature Set Dataset          MAE     R2\n",
      "0  Ridge Regression      Basketball Features    Test 4197284.3360 0.6927\n",
      "1  Ridge Regression  Non-Basketball Features    Test 3747815.8138 0.7522\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(random_state=42)\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Ridge Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(ridge, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "ridge_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                                 X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                                 y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best Ridge alpha (Basketball Features): {grid_search_basketball.best_params_['alpha']}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(ridge, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "ridge_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                           X_train_scaled, X_test_scaled, \n",
    "                           y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best Ridge alpha (Non-Basketball Features): {grid_search_full.best_params_['alpha']}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format) \n",
    "\n",
    "print(\"\\nRidge Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e0349-2b83-4164-85fb-8fd3be2e54dc",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a105afb-acfa-4aca-9fdb-9c9f10e2fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso alpha (Basketball Features): 100.0\n",
      "Best Lasso alpha (Non-Basketball Features): 100.0\n",
      "\n",
      "Lasso Regression Results:\n",
      "              Model              Feature Set Dataset          MAE     R2\n",
      "0  Lasso Regression      Basketball Features    Test 4184810.5377 0.6737\n",
      "1  Lasso Regression  Non-Basketball Features    Test 3684783.1455 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.485e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.895e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.485e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.895e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.638e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.483e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.612e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.884e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.349e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.193e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.454e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.084e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.888e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.899e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.447e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+15, tolerance: 2.703e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+15, tolerance: 2.977e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.751e+15, tolerance: 3.181e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e+15, tolerance: 2.933e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+15, tolerance: 2.756e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(random_state=42)\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Lasso Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(lasso, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "lasso_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                                 X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                                 y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best Lasso alpha (Basketball Features): {grid_search_basketball.best_params_['alpha']}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(lasso, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "lasso_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                           X_train_scaled, X_test_scaled, \n",
    "                           y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best Lasso alpha (Non-Basketball Features): {grid_search_full.best_params_['alpha']}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  \n",
    "\n",
    "print(\"\\nLasso Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfabba-d35c-4cc4-976f-ede76db77183",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16a850b2-7722-40df-8d19-e87e1f689de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params (Basketball Features): {'max_depth': 5, 'min_samples_split': 5}\n",
      "Best Decision Tree params (Non-Basketball Features): {'max_depth': 3, 'min_samples_split': 10}\n",
      "\n",
      "Decision Tree Regression Results:\n",
      "                      Model              Feature Set Dataset          MAE  \\\n",
      "0  Decision Tree Regression      Basketball Features    Test 3617525.2017   \n",
      "1  Decision Tree Regression  Non-Basketball Features    Test 3262377.8422   \n",
      "\n",
      "      R2  \n",
      "0 0.6441  \n",
      "1 0.7485  \n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Decision Tree Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(dt, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "dt_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                              X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                              y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best Decision Tree params (Basketball Features): {grid_search_basketball.best_params_}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(dt, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "dt_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                        X_train_scaled, X_test_scaled, \n",
    "                        y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best Decision Tree params (Non-Basketball Features): {grid_search_full.best_params_}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  \n",
    "\n",
    "print(\"\\nDecision Tree Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd841e9a-43c0-4356-8e6d-855eca8a1e72",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "30650df2-cefe-420b-80fe-e04967e70773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params (Basketball Features): {'max_depth': 10, 'n_estimators': 200}\n",
      "Best Random Forest params (Non-Basketball Features): {'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Regression Results:\n",
      "                      Model              Feature Set Dataset          MAE  \\\n",
      "0  Random Forest Regression      Basketball Features    Test 3291131.3222   \n",
      "1  Random Forest Regression  Non-Basketball Features    Test 2965484.4318   \n",
      "\n",
      "      R2  \n",
      "0 0.7580  \n",
      "1 0.8089  \n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Random Forest Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "rf_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                              X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                              y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best Random Forest params (Basketball Features): {grid_search_basketball.best_params_}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "rf_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                        X_train_scaled, X_test_scaled, \n",
    "                        y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best Random Forest params (Non-Basketball Features): {grid_search_full.best_params_}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  \n",
    "\n",
    "print(\"\\nRandom Forest Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4a086-8133-4620-aa12-0a5fea951078",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9623ad08-03fa-4762-99b0-2269fa7b5617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost params (Basketball Features): {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best XGBoost params (Non-Basketball Features): {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "XGBoost Regression Results:\n",
      "                Model              Feature Set Dataset          MAE     R2\n",
      "0  XGBoost Regression      Basketball Features    Test 3663381.0957 0.6868\n",
      "1  XGBoost Regression  Non-Basketball Features    Test 3280486.3362 0.7475\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'XGBoost Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(xgb, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "xgb_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                               X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                               y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best XGBoost params (Basketball Features): {grid_search_basketball.best_params_}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(xgb, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "xgb_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                         X_train_scaled, X_test_scaled, \n",
    "                         y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best XGBoost params (Non-Basketball Features): {grid_search_full.best_params_}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(\"\\nXGBoost Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6917f7-7105-4bb7-892b-1acb0e3f33a4",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5786899-3a60-4fc6-b887-36ef4ad0acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP params (Basketball Features): {'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP params (Non-Basketball Features): {'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.01}\n",
      "\n",
      "MLP Regression Results:\n",
      "            Model              Feature Set Dataset          MAE     R2\n",
      "0  MLP Regression      Basketball Features    Test 3436726.6366 0.7232\n",
      "1  MLP Regression  Non-Basketball Features    Test 3380124.7992 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(random_state=42, max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    model.fit(X_train, y_train.values.ravel())  \n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'MLP Regression',\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2\n",
    "    })\n",
    "    \n",
    "    return model\n",
    "\n",
    "grid_search_basketball = GridSearchCV(mlp, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "mlp_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                               X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                               y_train, y_test, 'Basketball Features')\n",
    "print(f\"Best MLP params (Basketball Features): {grid_search_basketball.best_params_}\")\n",
    "\n",
    "grid_search_full = GridSearchCV(mlp, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "mlp_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                         X_train_scaled, X_test_scaled, \n",
    "                         y_train, y_test, 'Non-Basketball Features')\n",
    "print(f\"Best MLP params (Non-Basketball Features): {grid_search_full.best_params_}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format) \n",
    "\n",
    "print(\"\\nMLP Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e6b4a-c264-4afd-88ee-225c9544f497",
   "metadata": {},
   "source": [
    "## 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "74f5bcd4-38b2-4511-ab02-9275e334e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature set shape: (354, 35, 1)\n",
      "Basketball feature set shape: (354, 28, 1)\n",
      "y_train shape: (354, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 1D CNN params (Basketball Features): {'batch_size': 8, 'model__dense_units': 95, 'model__dropout_rate_1': 0.4446612641953124, 'model__dropout_rate_2': 0.20282652208788698, 'model__dropout_rate_3': 0.3092249700165663, 'model__filters_1': 42, 'model__filters_2': 17, 'model__l2_reg': 0.014666566321361544, 'model__learning_rate': 0.0009837555188414592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 1D CNN params (Non-Basketball Features): {'batch_size': 8, 'model__dense_units': 95, 'model__dropout_rate_1': 0.4446612641953124, 'model__dropout_rate_2': 0.20282652208788698, 'model__dropout_rate_3': 0.3092249700165663, 'model__filters_1': 42, 'model__filters_2': 17, 'model__l2_reg': 0.014666566321361544, 'model__learning_rate': 0.0009837555188414592}\n",
      "\n",
      "1D CNN Regression Results:\n",
      "               Model              Feature Set Dataset          MAE     R2\n",
      "0  1D CNN Regression      Basketball Features    Test 4922436.1092 0.4263\n",
      "1  1D CNN Regression  Non-Basketball Features    Test 5224438.3778 0.3983\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "X_train_basketball_scaled = X_train_basketball_scaled.reshape(X_train_basketball_scaled.shape[0], X_train_basketball_scaled.shape[1], 1)\n",
    "X_test_basketball_scaled = X_test_basketball_scaled.reshape(X_test_basketball_scaled.shape[0], X_test_basketball_scaled.shape[1], 1)\n",
    "\n",
    "print(f\"Full feature set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Basketball feature set shape: {X_train_basketball_scaled.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "def create_cnn_model(learning_rate=0.001, l2_reg=0.01, dropout_rate_1=0.2, \n",
    "                     dropout_rate_2=0.2, dropout_rate_3=0.3, filters_1=32, \n",
    "                     filters_2=16, dense_units=50, input_dim=None):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=filters_1, kernel_size=3, activation='relu', \n",
    "                              input_shape=(input_dim, 1), padding='same'),\n",
    "        tf.keras.layers.Dropout(dropout_rate_1),\n",
    "        tf.keras.layers.Conv1D(filters=filters_2, kernel_size=3, activation='relu', \n",
    "                              padding='same'),\n",
    "        tf.keras.layers.Dropout(dropout_rate_2),\n",
    "        tf.keras.layers.GlobalMaxPooling1D(),\n",
    "        tf.keras.layers.Dense(dense_units, activation='relu', \n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        tf.keras.layers.Dropout(dropout_rate_3),\n",
    "        tf.keras.layers.Dense(1)  \n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set):\n",
    "    try:\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': '1D CNN Regression',\n",
    "            'Feature Set': feature_set,\n",
    "            'Dataset': 'Test',\n",
    "            'MAE': test_mae,\n",
    "            'R2': test_r2\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model for {feature_set}: {e}\")\n",
    "        results.append({\n",
    "            'Model': '1D CNN Regression',\n",
    "            'Feature Set': feature_set,\n",
    "            'Dataset': 'Test',\n",
    "            'MAE': np.nan,\n",
    "            'R2': np.nan\n",
    "        })\n",
    "    return model\n",
    "\n",
    "param_dist = {\n",
    "    'model__learning_rate': uniform(1e-5, 1e-3),  \n",
    "    'model__l2_reg': uniform(0.01, 0.1),         \n",
    "    'model__dropout_rate_1': uniform(0.2, 0.4),  \n",
    "    'model__dropout_rate_2': uniform(0.2, 0.4), \n",
    "    'model__dropout_rate_3': uniform(0.3, 0.4),  \n",
    "    'model__filters_1': randint(16, 64),        \n",
    "    'model__filters_2': randint(8, 32),         \n",
    "    'model__dense_units': randint(20, 100),     \n",
    "    'batch_size': [8, 16, 32]\n",
    "}\n",
    "\n",
    "try:\n",
    "    cnn_basketball = KerasRegressor(\n",
    "        model=create_cnn_model,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        input_dim=X_train_basketball_scaled.shape[1]\n",
    "    )\n",
    "    grid_search_basketball = RandomizedSearchCV(cnn_basketball, param_dist, n_iter=10, cv=3, \n",
    "                                               scoring='r2', n_jobs=1, random_state=42, \n",
    "                                               error_score='raise')\n",
    "    grid_search_basketball.fit(X_train_basketball_scaled, y_train.values.ravel())\n",
    "    cnn_basketball = evaluate_model(grid_search_basketball.best_estimator_, \n",
    "                                   X_train_basketball_scaled, X_test_basketball_scaled, \n",
    "                                   y_train, y_test, 'Basketball Features')\n",
    "    print(f\"Best 1D CNN params (Basketball Features): {grid_search_basketball.best_params_}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in randomized search (Basketball Features): {e}\")\n",
    "    cnn_basketball = None\n",
    "\n",
    "try:\n",
    "    cnn_full = KerasRegressor(\n",
    "        model=create_cnn_model,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        input_dim=X_train_scaled.shape[1]\n",
    "    )\n",
    "    grid_search_full = RandomizedSearchCV(cnn_full, param_dist, n_iter=10, cv=3, \n",
    "                                         scoring='r2', n_jobs=1, random_state=42, \n",
    "                                         error_score='raise')\n",
    "    grid_search_full.fit(X_train_scaled, y_train.values.ravel())\n",
    "    cnn_full = evaluate_model(grid_search_full.best_estimator_, \n",
    "                             X_train_scaled, X_test_scaled, \n",
    "                             y_train, y_test, 'Non-Basketball Features')\n",
    "    print(f\"Best 1D CNN params (Non-Basketball Features): {grid_search_full.best_params_}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in randomized search (Non-Basketball Features): {e}\")\n",
    "    cnn_full = None\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  \n",
    "\n",
    "print(\"\\n1D CNN Regression Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "37f33bb9-07bc-416f-802a-e141e5ffdef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset          MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4210336.7310 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3722742.0626 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4197284.3360 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3747815.8138 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4184810.5377 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3684783.1455 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3617525.2017 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3262377.8422 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3291131.3222 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2965484.4318 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3493630.8841 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2932422.1615 0.8174   \n",
      "12                MLP      Basketball Features    Test 3436726.6366 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3380124.7992 0.7316   \n",
      "\n",
      "                                         CV MAE Folds  CV MAE Mean  \n",
      "0   [3740826.6544753066, 4525841.746212794, 454417... 4081516.0553  \n",
      "1   [3691936.1307729594, 4462166.098131463, 426579... 3908233.2207  \n",
      "2   [3856472.1997101484, 4296475.835153485, 425433... 3908325.7285  \n",
      "3   [3834568.801955731, 4083235.10228124, 3806456.... 3666120.7148  \n",
      "4   [3761498.77580069, 4568600.4538105875, 4476517... 4063807.6556  \n",
      "5   [3708721.8400306096, 4512573.124213011, 425799... 3897063.7863  \n",
      "6   [4020540.0549034243, 4178112.6380699496, 41187... 3862583.5766  \n",
      "7   [3601064.0422656345, 3671415.9400215405, 37904... 3818064.3272  \n",
      "8   [2908631.7374258246, 3345985.6508251196, 33827... 3129194.3366  \n",
      "9   [2734816.9234012156, 3130814.25209741, 3286862... 2977631.0018  \n",
      "10  [3112488.0994718308, 3130537.014524648, 350706... 3121727.0620  \n",
      "11  [2698542.7502200706, 2628868.6285211267, 32386... 2854579.7238  \n",
      "12  [2970660.531245668, 3724806.6502319383, 344161... 3317780.4592  \n",
      "13  [3214596.677037668, 3861375.8586355415, 315583... 3260145.7121  \n",
      "\n",
      "Wilcoxon Test Results for MAE:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                    4081516.0553   \n",
      "1   Ridge Regression                    3908325.7285   \n",
      "2   Lasso Regression                    4063807.6556   \n",
      "3      Decision Tree                    3862583.5766   \n",
      "4      Random Forest                    3129194.3366   \n",
      "5            XGBoost                    3121727.0620   \n",
      "6                MLP                    3317780.4592   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  MAE p-value MAE Improved  \n",
      "0                        3908233.2207       0.0625           No  \n",
      "1                        3666120.7148       0.0625           No  \n",
      "2                        3897063.7863       0.0625           No  \n",
      "3                        3818064.3272       0.6250           No  \n",
      "4                        2977631.0018       0.0625           No  \n",
      "5                        2854579.7238       0.1250           No  \n",
      "6                        3260145.7121       0.6250           No  \n",
      "\n",
      "Models with Significant MAE Improvements (p < 0.05):\n",
      "No models showed significant MAE improvements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "alpha = 0.05  # Significance level for Wilcoxon test\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE scores\n",
    "    mae_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,\n",
    "        'CV MAE Mean': np.mean(mae_folds)\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds\n",
    "\n",
    "# Evaluate each model\n",
    "wilcoxon_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Wilcoxon test on CV MAE scores\n",
    "    stat_mae, p_value_mae = wilcoxon(mae_basketball_folds, mae_full_folds)\n",
    "    mae_improved = p_value_mae < alpha and np.mean(mae_full_folds) < np.mean(mae_basketball_folds)\n",
    "    \n",
    "    # Store Wilcoxon results\n",
    "    wilcoxon_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': np.mean(mae_basketball_folds),\n",
    "        'MAE Mean (Non-Basketball Features)': np.mean(mae_full_folds),\n",
    "        'MAE Wilcoxon Stat': stat_mae,\n",
    "        'MAE p-value': p_value_mae,\n",
    "        'MAE Improved': 'Yes' if mae_improved else 'No'\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Folds', 'CV MAE Mean']])\n",
    "\n",
    "print(\"\\nWilcoxon Test Results for MAE:\")\n",
    "print(wilcoxon_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                  'MAE p-value', 'MAE Improved']])\n",
    "\n",
    "# Highlight models with significant improvements\n",
    "print(\"\\nModels with Significant MAE Improvements (p < 0.05):\")\n",
    "improved_models = wilcoxon_df[wilcoxon_df['MAE Improved'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Improved']])\n",
    "else:\n",
    "    print(\"No models showed significant MAE improvements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7c38a821-31d9-4318-afeb-bf855ebb0571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE Mean (Basketball Features)</th>\n",
       "      <th>MAE Mean (Non-Basketball Features)</th>\n",
       "      <th>MAE Wilcoxon Stat</th>\n",
       "      <th>MAE p-value</th>\n",
       "      <th>MAE Improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4081516.0553</td>\n",
       "      <td>3908233.2207</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>3908325.7285</td>\n",
       "      <td>3666120.7148</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>4063807.6556</td>\n",
       "      <td>3897063.7863</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>3862583.5766</td>\n",
       "      <td>3818064.3272</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3129194.3366</td>\n",
       "      <td>2977631.0018</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3121727.0620</td>\n",
       "      <td>2854579.7238</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3317780.4592</td>\n",
       "      <td>3260145.7121</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  MAE Mean (Basketball Features)  \\\n",
       "0  Linear Regression                    4081516.0553   \n",
       "1   Ridge Regression                    3908325.7285   \n",
       "2   Lasso Regression                    4063807.6556   \n",
       "3      Decision Tree                    3862583.5766   \n",
       "4      Random Forest                    3129194.3366   \n",
       "5            XGBoost                    3121727.0620   \n",
       "6                MLP                    3317780.4592   \n",
       "\n",
       "   MAE Mean (Non-Basketball Features)  MAE Wilcoxon Stat  MAE p-value  \\\n",
       "0                        3908233.2207             0.0000       0.0625   \n",
       "1                        3666120.7148             0.0000       0.0625   \n",
       "2                        3897063.7863             0.0000       0.0625   \n",
       "3                        3818064.3272             5.0000       0.6250   \n",
       "4                        2977631.0018             0.0000       0.0625   \n",
       "5                        2854579.7238             1.0000       0.1250   \n",
       "6                        3260145.7121             5.0000       0.6250   \n",
       "\n",
       "  MAE Improved  \n",
       "0           No  \n",
       "1           No  \n",
       "2           No  \n",
       "3           No  \n",
       "4           No  \n",
       "5           No  \n",
       "6           No  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b0564aa3-ce20-45ef-ac80-c23b3a5848ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Linear Regression:\n",
      "Basketball Features MAE Folds: [3740826.6544753066, 4525841.746212794, 4544173.331069891, 4024244.544214685, 3572494.000443459]\n",
      "Non-Basketball Features MAE Folds: [3691936.1307729594, 4462166.098131463, 4265792.704575086, 3572444.788938163, 3548826.3809036976]\n",
      "Differences (Non-Basketball - Basketball): [ -48890.52370235  -63675.64808133 -278380.62649481 -451799.75527652\n",
      "  -23667.61953976]\n",
      "\n",
      "Diagnostics for Ridge Regression:\n",
      "Basketball Features MAE Folds: [3856472.1997101484, 4296475.835153485, 4254339.114513415, 3541549.241317412, 3592792.2520291978]\n",
      "Non-Basketball Features MAE Folds: [3834568.801955731, 4083235.10228124, 3806456.9753988083, 3099056.8104088404, 3507285.884081273]\n",
      "Differences (Non-Basketball - Basketball): [ -21903.39775442 -213240.73287224 -447882.13911461 -442492.43090857\n",
      "  -85506.36794792]\n",
      "\n",
      "Diagnostics for Lasso Regression:\n",
      "Basketball Features MAE Folds: [3761498.77580069, 4568600.4538105875, 4476517.21269577, 3947381.2088812203, 3565040.6268280954]\n",
      "Non-Basketball Features MAE Folds: [3708721.8400306096, 4512573.124213011, 4257993.615306718, 3495448.8981149043, 3510581.4538921313]\n",
      "Differences (Non-Basketball - Basketball): [ -52776.93577008  -56027.32959758 -218523.59738905 -451932.31076632\n",
      "  -54459.17293596]\n",
      "\n",
      "Diagnostics for Decision Tree:\n",
      "Basketball Features MAE Folds: [4020540.0549034243, 4178112.6380699496, 4118793.578028976, 4463997.059598501, 2531474.5521706403]\n",
      "Non-Basketball Features MAE Folds: [3601064.0422656345, 3671415.9400215405, 3790473.790160291, 3752321.1767241135, 4275046.687006992]\n",
      "Differences (Non-Basketball - Basketball): [-419476.01263779 -506696.69804841 -328319.78786869 -711675.88287439\n",
      " 1743572.13483635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Random Forest:\n",
      "Basketball Features MAE Folds: [2908631.7374258246, 3345985.6508251196, 3382798.984135942, 3320501.602502126, 2688053.708187382]\n",
      "Non-Basketball Features MAE Folds: [2734816.9234012156, 3130814.25209741, 3286862.5251, 3125710.5086939875, 2609950.7999196555]\n",
      "Differences (Non-Basketball - Basketball): [-173814.81402461 -215171.39872771  -95936.45903594 -194791.09380814\n",
      "  -78102.90826773]\n",
      "\n",
      "Diagnostics for XGBoost:\n",
      "Basketball Features MAE Folds: [3112488.0994718308, 3130537.014524648, 3507065.0669014086, 3287862.0827464787, 2570683.0464285715]\n",
      "Non-Basketball Features MAE Folds: [2698542.7502200706, 2628868.6285211267, 3238603.2288732394, 3021254.5994718308, 2685629.411941964]\n",
      "Differences (Non-Basketball - Basketball): [-413945.34925176 -501668.38600352 -268461.83802817 -266607.48327465\n",
      "  114946.36551339]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for MLP:\n",
      "Basketball Features MAE Folds: [2970660.531245668, 3724806.6502319383, 3441613.72742909, 3450227.443510462, 3001593.94381391]\n",
      "Non-Basketball Features MAE Folds: [3214596.677037668, 3861375.8586355415, 3155835.0684630987, 3183242.9543505115, 2885678.0020070416]\n",
      "Differences (Non-Basketball - Basketball): [ 243936.145792    136569.2084036  -285778.65896599 -266984.48915995\n",
      " -115915.94180687]\n",
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset          MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4210336.7310 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3722742.0626 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4197284.3360 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3747815.8138 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4184810.5377 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3684783.1455 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3617525.2017 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3262377.8422 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3291131.3222 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2965484.4318 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3493630.8841 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2932422.1615 0.8174   \n",
      "12                MLP      Basketball Features    Test 3436726.6366 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3380124.7992 0.7316   \n",
      "\n",
      "                                         CV MAE Folds  CV MAE Mean  \n",
      "0   [3740826.6544753066, 4525841.746212794, 454417... 4081516.0553  \n",
      "1   [3691936.1307729594, 4462166.098131463, 426579... 3908233.2207  \n",
      "2   [3856472.1997101484, 4296475.835153485, 425433... 3908325.7285  \n",
      "3   [3834568.801955731, 4083235.10228124, 3806456.... 3666120.7148  \n",
      "4   [3761498.77580069, 4568600.4538105875, 4476517... 4063807.6556  \n",
      "5   [3708721.8400306096, 4512573.124213011, 425799... 3897063.7863  \n",
      "6   [4020540.0549034243, 4178112.6380699496, 41187... 3862583.5766  \n",
      "7   [3601064.0422656345, 3671415.9400215405, 37904... 3818064.3272  \n",
      "8   [2908631.7374258246, 3345985.6508251196, 33827... 3129194.3366  \n",
      "9   [2734816.9234012156, 3130814.25209741, 3286862... 2977631.0018  \n",
      "10  [3112488.0994718308, 3130537.014524648, 350706... 3121727.0620  \n",
      "11  [2698542.7502200706, 2628868.6285211267, 32386... 2854579.7238  \n",
      "12  [2970660.531245668, 3724806.6502319383, 344161... 3317780.4592  \n",
      "13  [3214596.677037668, 3861375.8586355415, 315583... 3260145.7121  \n",
      "\n",
      "Wilcoxon Test Results for MAE:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                    4081516.0553   \n",
      "1   Ridge Regression                    3908325.7285   \n",
      "2   Lasso Regression                    4063807.6556   \n",
      "3      Decision Tree                    3862583.5766   \n",
      "4      Random Forest                    3129194.3366   \n",
      "5            XGBoost                    3121727.0620   \n",
      "6                MLP                    3317780.4592   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  MAE p-value MAE Improved  \n",
      "0                        3908233.2207       0.0625           No  \n",
      "1                        3666120.7148       0.0625           No  \n",
      "2                        3897063.7863       0.0625           No  \n",
      "3                        3818064.3272       0.6250           No  \n",
      "4                        2977631.0018       0.0625           No  \n",
      "5                        2854579.7238       0.1250           No  \n",
      "6                        3260145.7121       0.6250           No  \n",
      "\n",
      "Models with Significant MAE Improvements (p < 0.05):\n",
      "No models showed significant MAE improvements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "alpha = 0.05  # Significance level for Wilcoxon test\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE scores\n",
    "    mae_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae,\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,\n",
    "        'CV MAE Mean': np.mean(mae_folds)\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds\n",
    "\n",
    "# Evaluate each model and collect MAE scores\n",
    "wilcoxon_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Diagnostics: Print MAE scores and differences\n",
    "    print(f\"\\nDiagnostics for {name}:\")\n",
    "    print(f\"Basketball Features MAE Folds: {mae_basketball_folds}\")\n",
    "    print(f\"Non-Basketball Features MAE Folds: {mae_full_folds}\")\n",
    "    print(f\"Differences (Non-Basketball - Basketball): {np.array(mae_full_folds) - np.array(mae_basketball_folds)}\")\n",
    "    \n",
    "    # Wilcoxon test on CV MAE scores\n",
    "    stat_mae, p_value_mae = wilcoxon(mae_basketball_folds, mae_full_folds)\n",
    "    mae_improved = p_value_mae < alpha and np.mean(mae_full_folds) < np.mean(mae_basketball_folds)\n",
    "    \n",
    "    # Store Wilcoxon results\n",
    "    wilcoxon_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': np.mean(mae_basketball_folds),\n",
    "        'MAE Mean (Non-Basketball Features)': np.mean(mae_full_folds),\n",
    "        'MAE Wilcoxon Stat': stat_mae,\n",
    "        'MAE p-value': p_value_mae,\n",
    "        'MAE Improved': 'Yes' if mae_improved else 'No'\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Folds', 'CV MAE Mean']])\n",
    "\n",
    "print(\"\\nWilcoxon Test Results for MAE:\")\n",
    "print(wilcoxon_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                  'MAE p-value', 'MAE Improved']])\n",
    "\n",
    "# Highlight models with significant improvements\n",
    "print(\"\\nModels with Significant MAE Improvements (p < 0.05):\")\n",
    "improved_models = wilcoxon_df[wilcoxon_df['MAE Improved'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Improved']])\n",
    "else:\n",
    "    print(\"No models showed significant MAE improvements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "71d78ad4-ba04-49ad-b6bc-6ac81b91a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Linear Regression:\n",
      "Basketball Features MAE Folds: ['3740826.65', '4525841.75', '4544173.33', '4024244.54', '3572494.00']\n",
      "Non-Basketball Features MAE Folds: ['3691936.13', '4462166.10', '4265792.70', '3572444.79', '3548826.38']\n",
      "Differences (Non-Basketball - Basketball): ['-48890.52', '-63675.65', '-278380.63', '-451799.76', '-23667.62']\n",
      "\n",
      "Diagnostics for Ridge Regression:\n",
      "Basketball Features MAE Folds: ['3856472.20', '4296475.84', '4254339.11', '3541549.24', '3592792.25']\n",
      "Non-Basketball Features MAE Folds: ['3834568.80', '4083235.10', '3806456.98', '3099056.81', '3507285.88']\n",
      "Differences (Non-Basketball - Basketball): ['-21903.40', '-213240.73', '-447882.14', '-442492.43', '-85506.37']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Lasso Regression:\n",
      "Basketball Features MAE Folds: ['3761498.78', '4568600.45', '4476517.21', '3947381.21', '3565040.63']\n",
      "Non-Basketball Features MAE Folds: ['3708721.84', '4512573.12', '4257993.62', '3495448.90', '3510581.45']\n",
      "Differences (Non-Basketball - Basketball): ['-52776.94', '-56027.33', '-218523.60', '-451932.31', '-54459.17']\n",
      "\n",
      "Diagnostics for Decision Tree:\n",
      "Basketball Features MAE Folds: ['4020540.05', '4178112.64', '4118793.58', '4463997.06', '2531474.55']\n",
      "Non-Basketball Features MAE Folds: ['3601064.04', '3671415.94', '3790473.79', '3752321.18', '4275046.69']\n",
      "Differences (Non-Basketball - Basketball): ['-419476.01', '-506696.70', '-328319.79', '-711675.88', '1743572.13']\n",
      "\n",
      "Diagnostics for Random Forest:\n",
      "Basketball Features MAE Folds: ['2908631.74', '3345985.65', '3382798.98', '3320501.60', '2688053.71']\n",
      "Non-Basketball Features MAE Folds: ['2734816.92', '3130814.25', '3286862.53', '3125710.51', '2609950.80']\n",
      "Differences (Non-Basketball - Basketball): ['-173814.81', '-215171.40', '-95936.46', '-194791.09', '-78102.91']\n",
      "\n",
      "Diagnostics for XGBoost:\n",
      "Basketball Features MAE Folds: ['3112488.10', '3130537.01', '3507065.07', '3287862.08', '2570683.05']\n",
      "Non-Basketball Features MAE Folds: ['2698542.75', '2628868.63', '3238603.23', '3021254.60', '2685629.41']\n",
      "Differences (Non-Basketball - Basketball): ['-413945.35', '-501668.39', '-268461.84', '-266607.48', '114946.37']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for MLP:\n",
      "Basketball Features MAE Folds: ['2970660.53', '3724806.65', '3441613.73', '3450227.44', '3001593.94']\n",
      "Non-Basketball Features MAE Folds: ['3214596.68', '3861375.86', '3155835.07', '3183242.95', '2885678.00']\n",
      "Differences (Non-Basketball - Basketball): ['243936.15', '136569.21', '-285778.66', '-266984.49', '-115915.94']\n",
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset    MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4.2103 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3.7227 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4.1973 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3.7478 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4.1848 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3.6848 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3.6175 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3.2624 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3.2911 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2.9655 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3.4936 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2.9324 0.8174   \n",
      "12                MLP      Basketball Features    Test 3.4367 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3.3801 0.7316   \n",
      "\n",
      "                                         CV MAE Folds  CV MAE Mean  \n",
      "0   [3740826.6544753066, 4525841.746212794, 454417...       4.0815  \n",
      "1   [3691936.1307729594, 4462166.098131463, 426579...       3.9082  \n",
      "2   [3856472.1997101484, 4296475.835153485, 425433...       3.9083  \n",
      "3   [3834568.801955731, 4083235.10228124, 3806456....       3.6661  \n",
      "4   [3761498.77580069, 4568600.4538105875, 4476517...       4.0638  \n",
      "5   [3708721.8400306096, 4512573.124213011, 425799...       3.8971  \n",
      "6   [4020540.0549034243, 4178112.6380699496, 41187...       3.8626  \n",
      "7   [3601064.0422656345, 3671415.9400215405, 37904...       3.8181  \n",
      "8   [2908631.7374258246, 3345985.6508251196, 33827...       3.1292  \n",
      "9   [2734816.9234012156, 3130814.25209741, 3286862...       2.9776  \n",
      "10  [3112488.0994718308, 3130537.014524648, 350706...       3.1217  \n",
      "11  [2698542.7502200706, 2628868.6285211267, 32386...       2.8546  \n",
      "12  [2970660.531245668, 3724806.6502319383, 344161...       3.3178  \n",
      "13  [3214596.677037668, 3861375.8586355415, 315583...       3.2601  \n",
      "\n",
      "Wilcoxon Test Results for MAE:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                    4081516.0553   \n",
      "1   Ridge Regression                    3908325.7285   \n",
      "2   Lasso Regression                    4063807.6556   \n",
      "3      Decision Tree                    3862583.5766   \n",
      "4      Random Forest                    3129194.3366   \n",
      "5            XGBoost                    3121727.0620   \n",
      "6                MLP                    3317780.4592   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  MAE p-value MAE Improved  \n",
      "0                        3908233.2207       0.0625           No  \n",
      "1                        3666120.7148       0.0625           No  \n",
      "2                        3897063.7863       0.0625           No  \n",
      "3                        3818064.3272       0.6250           No  \n",
      "4                        2977631.0018       0.0625           No  \n",
      "5                        2854579.7238       0.1250           No  \n",
      "6                        3260145.7121       0.6250           No  \n",
      "\n",
      "Models with Significant MAE Improvements (p < 0.05):\n",
      "No models showed significant MAE improvements.\n",
      "\n",
      "Target Variable Diagnostics:\n",
      "y_train stats:              Salary\n",
      "count      354.0000\n",
      "mean   8415441.3588\n",
      "std   10152411.9406\n",
      "min      19186.0000\n",
      "25%    1782621.0000\n",
      "50%    4000000.0000\n",
      "75%   11539524.5000\n",
      "max   45780966.0000\n",
      "y_test stats:              Salary\n",
      "count       89.0000\n",
      "mean   8018585.4045\n",
      "std    9985556.7713\n",
      "min      85578.0000\n",
      "25%    1701593.0000\n",
      "50%    3300000.0000\n",
      "75%   10500000.0000\n",
      "max   44211146.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5  # Try cv_folds = 10 for more power\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "alpha = 0.05  # Significance level\n",
    "mae_scale = 1_000_000  # Scale MAE for display (does not affect Wilcoxon test)\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE scores\n",
    "    mae_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results (scale MAE for display)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae / mae_scale,  # Scaled for display\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,  # Raw values for Wilcoxon\n",
    "        'CV MAE Mean': np.mean(mae_folds) / mae_scale  # Scaled for display\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds\n",
    "\n",
    "# Evaluate each model and collect MAE scores\n",
    "wilcoxon_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Diagnostics: Print MAE scores and differences\n",
    "    print(f\"\\nDiagnostics for {name}:\")\n",
    "    print(f\"Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_basketball_folds]}\")\n",
    "    print(f\"Non-Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_full_folds]}\")\n",
    "    differences = np.array(mae_full_folds) - np.array(mae_basketball_folds)\n",
    "    print(f\"Differences (Non-Basketball - Basketball): {[f'{diff:.2f}' for diff in differences]}\")\n",
    "    \n",
    "    # Wilcoxon test on CV MAE scores\n",
    "    stat_mae, p_value_mae = wilcoxon(mae_basketball_folds, mae_full_folds)\n",
    "    mae_improved = p_value_mae < alpha and np.mean(mae_full_folds) < np.mean(mae_basketball_folds)\n",
    "    \n",
    "    # Store Wilcoxon results\n",
    "    wilcoxon_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': np.mean(mae_basketball_folds),\n",
    "        'MAE Mean (Non-Basketball Features)': np.mean(mae_full_folds),\n",
    "        'MAE Wilcoxon Stat': stat_mae,\n",
    "        'MAE p-value': p_value_mae,\n",
    "        'MAE Improved': 'Yes' if mae_improved else 'No'\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Folds', 'CV MAE Mean']])\n",
    "\n",
    "print(\"\\nWilcoxon Test Results for MAE:\")\n",
    "print(wilcoxon_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                  'MAE p-value', 'MAE Improved']])\n",
    "\n",
    "# Highlight models with significant improvements\n",
    "print(\"\\nModels with Significant MAE Improvements (p < 0.05):\")\n",
    "improved_models = wilcoxon_df[wilcoxon_df['MAE Improved'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Improved']])\n",
    "else:\n",
    "    print(\"No models showed significant MAE improvements.\")\n",
    "\n",
    "# Target variable diagnostics\n",
    "print(\"\\nTarget Variable Diagnostics:\")\n",
    "print(\"y_train stats:\", y_train.describe())\n",
    "print(\"y_test stats:\", y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80abc205-bcf4-4f49-8d2e-86001cfd92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Linear Regression:\n",
      "Basketball Features MAE Folds: ['3740826.65', '4525841.75', '4544173.33', '4024244.54', '3572494.00']\n",
      "Non-Basketball Features MAE Folds: ['3691936.13', '4462166.10', '4265792.70', '3572444.79', '3548826.38']\n",
      "Differences (Non-Basketball - Basketball): ['-48890.52', '-63675.65', '-278380.63', '-451799.76', '-23667.62']\n",
      "Differences Mean: -173282.83, Std: 166426.63\n",
      "\n",
      "Diagnostics for Ridge Regression:\n",
      "Basketball Features MAE Folds: ['3856472.20', '4296475.84', '4254339.11', '3541549.24', '3592792.25']\n",
      "Non-Basketball Features MAE Folds: ['3834568.80', '4083235.10', '3806456.98', '3099056.81', '3507285.88']\n",
      "Differences (Non-Basketball - Basketball): ['-21903.40', '-213240.73', '-447882.14', '-442492.43', '-85506.37']\n",
      "Differences Mean: -242205.01, Std: 176830.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Lasso Regression:\n",
      "Basketball Features MAE Folds: ['3761498.78', '4568600.45', '4476517.21', '3947381.21', '3565040.63']\n",
      "Non-Basketball Features MAE Folds: ['3708721.84', '4512573.12', '4257993.62', '3495448.90', '3510581.45']\n",
      "Differences (Non-Basketball - Basketball): ['-52776.94', '-56027.33', '-218523.60', '-451932.31', '-54459.17']\n",
      "Differences Mean: -166743.87, Std: 156120.50\n",
      "\n",
      "Diagnostics for Decision Tree:\n",
      "Basketball Features MAE Folds: ['4020540.05', '4178112.64', '4118793.58', '4463997.06', '2531474.55']\n",
      "Non-Basketball Features MAE Folds: ['3601064.04', '3671415.94', '3790473.79', '3752321.18', '4275046.69']\n",
      "Differences (Non-Basketball - Basketball): ['-419476.01', '-506696.70', '-328319.79', '-711675.88', '1743572.13']\n",
      "Differences Mean: -44519.25, Std: 903007.43\n",
      "\n",
      "Diagnostics for Random Forest:\n",
      "Basketball Features MAE Folds: ['2908631.74', '3345985.65', '3382798.98', '3320501.60', '2688053.71']\n",
      "Non-Basketball Features MAE Folds: ['2734816.92', '3130814.25', '3286862.53', '3125710.51', '2609950.80']\n",
      "Differences (Non-Basketball - Basketball): ['-173814.81', '-215171.40', '-95936.46', '-194791.09', '-78102.91']\n",
      "Differences Mean: -151563.33, Std: 54590.36\n",
      "\n",
      "Diagnostics for XGBoost:\n",
      "Basketball Features MAE Folds: ['3112488.10', '3130537.01', '3507065.07', '3287862.08', '2570683.05']\n",
      "Non-Basketball Features MAE Folds: ['2698542.75', '2628868.63', '3238603.23', '3021254.60', '2685629.41']\n",
      "Differences (Non-Basketball - Basketball): ['-413945.35', '-501668.39', '-268461.84', '-266607.48', '114946.37']\n",
      "Differences Mean: -267147.34, Std: 210972.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for MLP:\n",
      "Basketball Features MAE Folds: ['2970660.53', '3724806.65', '3441613.73', '3450227.44', '3001593.94']\n",
      "Non-Basketball Features MAE Folds: ['3214596.68', '3861375.86', '3155835.07', '3183242.95', '2885678.00']\n",
      "Differences (Non-Basketball - Basketball): ['243936.15', '136569.21', '-285778.66', '-266984.49', '-115915.94']\n",
      "Differences Mean: -57634.75, Std: 213510.58\n",
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset    MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4.2103 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3.7227 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4.1973 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3.7478 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4.1848 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3.6848 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3.6175 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3.2624 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3.2911 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2.9655 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3.4936 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2.9324 0.8174   \n",
      "12                MLP      Basketball Features    Test 3.4367 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3.3801 0.7316   \n",
      "\n",
      "                                         CV MAE Folds  CV MAE Mean  \n",
      "0   [3740826.6544753066, 4525841.746212794, 454417...       4.0815  \n",
      "1   [3691936.1307729594, 4462166.098131463, 426579...       3.9082  \n",
      "2   [3856472.1997101484, 4296475.835153485, 425433...       3.9083  \n",
      "3   [3834568.801955731, 4083235.10228124, 3806456....       3.6661  \n",
      "4   [3761498.77580069, 4568600.4538105875, 4476517...       4.0638  \n",
      "5   [3708721.8400306096, 4512573.124213011, 425799...       3.8971  \n",
      "6   [4020540.0549034243, 4178112.6380699496, 41187...       3.8626  \n",
      "7   [3601064.0422656345, 3671415.9400215405, 37904...       3.8181  \n",
      "8   [2908631.7374258246, 3345985.6508251196, 33827...       3.1292  \n",
      "9   [2734816.9234012156, 3130814.25209741, 3286862...       2.9776  \n",
      "10  [3112488.0994718308, 3130537.014524648, 350706...       3.1217  \n",
      "11  [2698542.7502200706, 2628868.6285211267, 32386...       2.8546  \n",
      "12  [2970660.531245668, 3724806.6502319383, 344161...       3.3178  \n",
      "13  [3214596.677037668, 3861375.8586355415, 315583...       3.2601  \n",
      "\n",
      "Paired t-test Results for MAE:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                    4081516.0553   \n",
      "1   Ridge Regression                    3908325.7285   \n",
      "2   Lasso Regression                    4063807.6556   \n",
      "3      Decision Tree                    3862583.5766   \n",
      "4      Random Forest                    3129194.3366   \n",
      "5            XGBoost                    3121727.0620   \n",
      "6                MLP                    3317780.4592   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  t-test Statistic  t-test p-value  \\\n",
      "0                        3908233.2207            2.0824          0.1057   \n",
      "1                        3666120.7148            2.7394          0.0519   \n",
      "2                        3897063.7863            2.1361          0.0995   \n",
      "3                        3818064.3272            0.0986          0.9262   \n",
      "4                        2977631.0018            5.5528          0.0051   \n",
      "5                        2854579.7238            2.5325          0.0645   \n",
      "6                        3260145.7121            0.5399          0.6179   \n",
      "\n",
      "  MAE Improved  \n",
      "0           No  \n",
      "1           No  \n",
      "2           No  \n",
      "3           No  \n",
      "4          Yes  \n",
      "5           No  \n",
      "6           No  \n",
      "\n",
      "Models with Significant MAE Improvements (p < 0.05):\n",
      "           Model MAE Improved\n",
      "4  Random Forest          Yes\n",
      "\n",
      "Target Variable Diagnostics:\n",
      "y_train stats:              Salary\n",
      "count      354.0000\n",
      "mean   8415441.3588\n",
      "std   10152411.9406\n",
      "min      19186.0000\n",
      "25%    1782621.0000\n",
      "50%    4000000.0000\n",
      "75%   11539524.5000\n",
      "max   45780966.0000\n",
      "y_test stats:              Salary\n",
      "count       89.0000\n",
      "mean   8018585.4045\n",
      "std    9985556.7713\n",
      "min      85578.0000\n",
      "25%    1701593.0000\n",
      "50%    3300000.0000\n",
      "75%   10500000.0000\n",
      "max   44211146.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import ttest_rel\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5  # Can set to 10 for more power\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "alpha = 0.05  # Significance level\n",
    "mae_scale = 1_000_000  # Scale MAE for display\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE scores\n",
    "    mae_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results (scale MAE for display)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae / mae_scale,\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,  # Raw values for t-test\n",
    "        'CV MAE Mean': np.mean(mae_folds) / mae_scale\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds\n",
    "\n",
    "# Evaluate each model and collect MAE scores\n",
    "ttest_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Diagnostics: Print MAE scores and differences\n",
    "    print(f\"\\nDiagnostics for {name}:\")\n",
    "    print(f\"Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_basketball_folds]}\")\n",
    "    print(f\"Non-Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_full_folds]}\")\n",
    "    differences = np.array(mae_full_folds) - np.array(mae_basketball_folds)\n",
    "    print(f\"Differences (Non-Basketball - Basketball): {[f'{diff:.2f}' for diff in differences]}\")\n",
    "    print(f\"Differences Mean: {np.mean(differences):.2f}, Std: {np.std(differences):.2f}\")\n",
    "    \n",
    "    # Paired t-test on CV MAE scores\n",
    "    stat_t, p_value_t = ttest_rel(mae_basketball_folds, mae_full_folds)\n",
    "    mae_improved = p_value_t < alpha and np.mean(mae_full_folds) < np.mean(mae_basketball_folds)\n",
    "    \n",
    "    # Store t-test results\n",
    "    ttest_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': np.mean(mae_basketball_folds),\n",
    "        'MAE Mean (Non-Basketball Features)': np.mean(mae_full_folds),\n",
    "        't-test Statistic': stat_t,\n",
    "        't-test p-value': p_value_t,\n",
    "        'MAE Improved': 'Yes' if mae_improved else 'No'\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "ttest_df = pd.DataFrame(ttest_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Folds', 'CV MAE Mean']])\n",
    "\n",
    "print(\"\\nPaired t-test Results for MAE:\")\n",
    "print(ttest_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                't-test Statistic', 't-test p-value', 'MAE Improved']])\n",
    "\n",
    "# Highlight models with significant improvements\n",
    "print(\"\\nModels with Significant MAE Improvements (p < 0.05):\")\n",
    "improved_models = ttest_df[ttest_df['MAE Improved'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Improved']])\n",
    "else:\n",
    "    print(\"No models showed significant MAE improvements.\")\n",
    "\n",
    "# Target variable diagnostics\n",
    "print(\"\\nTarget Variable Diagnostics:\")\n",
    "print(\"y_train stats:\", y_train.describe())\n",
    "print(\"y_test stats:\", y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b1cf399a-11c4-4d62-bc2f-0aac7e021717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE Mean (Basketball Features)</th>\n",
       "      <th>MAE Mean (Non-Basketball Features)</th>\n",
       "      <th>t-test Statistic</th>\n",
       "      <th>t-test p-value</th>\n",
       "      <th>MAE Improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4081516.0553</td>\n",
       "      <td>3908233.2207</td>\n",
       "      <td>2.0824</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>3908325.7285</td>\n",
       "      <td>3666120.7148</td>\n",
       "      <td>2.7394</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>4063807.6556</td>\n",
       "      <td>3897063.7863</td>\n",
       "      <td>2.1361</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>3862583.5766</td>\n",
       "      <td>3818064.3272</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3129194.3366</td>\n",
       "      <td>2977631.0018</td>\n",
       "      <td>5.5528</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3121727.0620</td>\n",
       "      <td>2854579.7238</td>\n",
       "      <td>2.5325</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3317780.4592</td>\n",
       "      <td>3260145.7121</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  MAE Mean (Basketball Features)  \\\n",
       "0  Linear Regression                    4081516.0553   \n",
       "1   Ridge Regression                    3908325.7285   \n",
       "2   Lasso Regression                    4063807.6556   \n",
       "3      Decision Tree                    3862583.5766   \n",
       "4      Random Forest                    3129194.3366   \n",
       "5            XGBoost                    3121727.0620   \n",
       "6                MLP                    3317780.4592   \n",
       "\n",
       "   MAE Mean (Non-Basketball Features)  t-test Statistic  t-test p-value  \\\n",
       "0                        3908233.2207            2.0824          0.1057   \n",
       "1                        3666120.7148            2.7394          0.0519   \n",
       "2                        3897063.7863            2.1361          0.0995   \n",
       "3                        3818064.3272            0.0986          0.9262   \n",
       "4                        2977631.0018            5.5528          0.0051   \n",
       "5                        2854579.7238            2.5325          0.0645   \n",
       "6                        3260145.7121            0.5399          0.6179   \n",
       "\n",
       "  MAE Improved  \n",
       "0           No  \n",
       "1           No  \n",
       "2           No  \n",
       "3           No  \n",
       "4          Yes  \n",
       "5           No  \n",
       "6           No  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0dff9dae-384a-40e6-97fa-b2e42d5f6bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Linear Regression:\n",
      "Basketball Features MAE Folds: ['3740826.65', '4525841.75', '4544173.33', '4024244.54', '3572494.00']\n",
      "Non-Basketball Features MAE Folds: ['3691936.13', '4462166.10', '4265792.70', '3572444.79', '3548826.38']\n",
      "MAE Differences (Basketball - Non-Basketball): ['48890.52', '63675.65', '278380.63', '451799.76', '23667.62']\n",
      "Basketball Features R2 Folds: ['0.7937', '0.5042', '0.6558', '0.5567', '0.7500']\n",
      "Non-Basketball Features R2 Folds: ['0.7987', '0.5291', '0.6621', '0.6396', '0.7570']\n",
      "\n",
      "Diagnostics for Ridge Regression:\n",
      "Basketball Features MAE Folds: ['3856472.20', '4296475.84', '4254339.11', '3541549.24', '3592792.25']\n",
      "Non-Basketball Features MAE Folds: ['3834568.80', '4083235.10', '3806456.98', '3099056.81', '3507285.88']\n",
      "MAE Differences (Basketball - Non-Basketball): ['21903.40', '213240.73', '447882.14', '442492.43', '85506.37']\n",
      "Basketball Features R2 Folds: ['0.7785', '0.5808', '0.7141', '0.6631', '0.7397']\n",
      "Non-Basketball Features R2 Folds: ['0.7834', '0.5965', '0.7375', '0.7217', '0.7727']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Lasso Regression:\n",
      "Basketball Features MAE Folds: ['3761498.78', '4568600.45', '4476517.21', '3947381.21', '3565040.63']\n",
      "Non-Basketball Features MAE Folds: ['3708721.84', '4512573.12', '4257993.62', '3495448.90', '3510581.45']\n",
      "MAE Differences (Basketball - Non-Basketball): ['52776.94', '56027.33', '218523.60', '451932.31', '54459.17']\n",
      "Basketball Features R2 Folds: ['0.7892', '0.4979', '0.6648', '0.5711', '0.7544']\n",
      "Non-Basketball Features R2 Folds: ['0.7926', '0.5214', '0.6581', '0.6490', '0.7666']\n",
      "\n",
      "Diagnostics for Decision Tree:\n",
      "Basketball Features MAE Folds: ['4020540.05', '4178112.64', '4118793.58', '4463997.06', '2531474.55']\n",
      "Non-Basketball Features MAE Folds: ['3601064.04', '3671415.94', '3790473.79', '3752321.18', '4275046.69']\n",
      "MAE Differences (Basketball - Non-Basketball): ['419476.01', '506696.70', '328319.79', '711675.88', '-1743572.13']\n",
      "Basketball Features R2 Folds: ['0.6274', '0.4292', '0.6300', '0.3321', '0.9001']\n",
      "Non-Basketball Features R2 Folds: ['0.7291', '0.6673', '0.6480', '0.5363', '0.6280']\n",
      "\n",
      "Diagnostics for Random Forest:\n",
      "Basketball Features MAE Folds: ['2908631.74', '3345985.65', '3382798.98', '3320501.60', '2688053.71']\n",
      "Non-Basketball Features MAE Folds: ['2734816.92', '3130814.25', '3286862.53', '3125710.51', '2609950.80']\n",
      "MAE Differences (Basketball - Non-Basketball): ['173814.81', '215171.40', '95936.46', '194791.09', '78102.91']\n",
      "Basketball Features R2 Folds: ['0.8335', '0.7031', '0.7548', '0.6187', '0.8632']\n",
      "Non-Basketball Features R2 Folds: ['0.8496', '0.7628', '0.7549', '0.6430', '0.8834']\n",
      "\n",
      "Diagnostics for XGBoost:\n",
      "Basketball Features MAE Folds: ['3112488.10', '3130537.01', '3507065.07', '3287862.08', '2570683.05']\n",
      "Non-Basketball Features MAE Folds: ['2698542.75', '2628868.63', '3238603.23', '3021254.60', '2685629.41']\n",
      "MAE Differences (Basketball - Non-Basketball): ['413945.35', '501668.39', '268461.84', '266607.48', '-114946.37']\n",
      "Basketball Features R2 Folds: ['0.8264', '0.6844', '0.7176', '0.6406', '0.8693']\n",
      "Non-Basketball Features R2 Folds: ['0.8493', '0.8366', '0.7323', '0.6350', '0.8146']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for MLP:\n",
      "Basketball Features MAE Folds: ['2970660.53', '3724806.65', '3441613.73', '3450227.44', '3001593.94']\n",
      "Non-Basketball Features MAE Folds: ['3214596.68', '3861375.86', '3155835.07', '3183242.95', '2885678.00']\n",
      "MAE Differences (Basketball - Non-Basketball): ['-243936.15', '-136569.21', '285778.66', '266984.49', '115915.94']\n",
      "Basketball Features R2 Folds: ['0.8042', '0.6102', '0.7595', '0.6405', '0.7912']\n",
      "Non-Basketball Features R2 Folds: ['0.7677', '0.6119', '0.7669', '0.6916', '0.8090']\n",
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset    MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4.2103 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3.7227 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4.1973 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3.7478 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4.1848 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3.6848 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3.6175 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3.2624 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3.2911 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2.9655 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3.4936 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2.9324 0.8174   \n",
      "12                MLP      Basketball Features    Test 3.4367 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3.3801 0.7316   \n",
      "\n",
      "    CV MAE Mean  CV R2 Mean  \n",
      "0        4.0815      0.6521  \n",
      "1        3.9082      0.6773  \n",
      "2        3.9083      0.6952  \n",
      "3        3.6661      0.7223  \n",
      "4        4.0638      0.6555  \n",
      "5        3.8971      0.6775  \n",
      "6        3.8626      0.5837  \n",
      "7        3.8181      0.6418  \n",
      "8        3.1292      0.7547  \n",
      "9        2.9776      0.7787  \n",
      "10       3.1217      0.7477  \n",
      "11       2.8546      0.7736  \n",
      "12       3.3178      0.7211  \n",
      "13       3.2601      0.7294  \n",
      "\n",
      "Predictive Power Comparison:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                          4.0815   \n",
      "1   Ridge Regression                          3.9083   \n",
      "2   Lasso Regression                          4.0638   \n",
      "3      Decision Tree                          3.8626   \n",
      "4      Random Forest                          3.1292   \n",
      "5            XGBoost                          3.1217   \n",
      "6                MLP                          3.3178   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  MAE Difference  MAE % Improvement  \\\n",
      "0                              3.9082          0.1733             4.2456   \n",
      "1                              3.6661          0.2422             6.1972   \n",
      "2                              3.8971          0.1667             4.1031   \n",
      "3                              3.8181          0.0445             1.1526   \n",
      "4                              2.9776          0.1516             4.8435   \n",
      "5                              2.8546          0.2671             8.5577   \n",
      "6                              3.2601          0.0576             1.7371   \n",
      "\n",
      "   Folds Improved (MAE)  R2 Mean (Basketball Features)  \\\n",
      "0                     5                         0.6521   \n",
      "1                     5                         0.6952   \n",
      "2                     5                         0.6555   \n",
      "3                     4                         0.5837   \n",
      "4                     5                         0.7547   \n",
      "5                     4                         0.7477   \n",
      "6                     3                         0.7211   \n",
      "\n",
      "   R2 Mean (Non-Basketball Features)  R2 Difference Improved Predictive Power  \n",
      "0                             0.6773         0.0252                       Yes  \n",
      "1                             0.7223         0.0271                       Yes  \n",
      "2                             0.6775         0.0221                       Yes  \n",
      "3                             0.6418         0.0580                       Yes  \n",
      "4                             0.7787         0.0241                       Yes  \n",
      "5                             0.7736         0.0259                       Yes  \n",
      "6                             0.7294         0.0083                       Yes  \n",
      "\n",
      "Models with Improved Predictive Power (Lower MAE):\n",
      "               Model  MAE Difference  MAE % Improvement  Folds Improved (MAE)\n",
      "0  Linear Regression          0.1733             4.2456                     5\n",
      "1   Ridge Regression          0.2422             6.1972                     5\n",
      "2   Lasso Regression          0.1667             4.1031                     5\n",
      "3      Decision Tree          0.0445             1.1526                     4\n",
      "4      Random Forest          0.1516             4.8435                     5\n",
      "5            XGBoost          0.2671             8.5577                     4\n",
      "6                MLP          0.0576             1.7371                     3\n",
      "\n",
      "Target Variable Diagnostics:\n",
      "y_train stats:              Salary\n",
      "count      354.0000\n",
      "mean   8415441.3588\n",
      "std   10152411.9406\n",
      "min      19186.0000\n",
      "25%    1782621.0000\n",
      "50%    4000000.0000\n",
      "75%   11539524.5000\n",
      "max   45780966.0000\n",
      "y_test stats:              Salary\n",
      "count       89.0000\n",
      "mean   8018585.4045\n",
      "std    9985556.7713\n",
      "min      85578.0000\n",
      "25%    1701593.0000\n",
      "50%    3300000.0000\n",
      "75%   10500000.0000\n",
      "max   44211146.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "mae_scale = 1_000_000  # Scale MAE for display\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE and R2 scores\n",
    "    mae_folds = []\n",
    "    r2_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "        r2_folds.append(r2_score(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results (scale MAE for display)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae / mae_scale,\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,  # Raw values\n",
    "        'CV MAE Mean': np.mean(mae_folds) / mae_scale,\n",
    "        'CV R2 Folds': r2_folds,\n",
    "        'CV R2 Mean': np.mean(r2_folds)\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds, r2_folds\n",
    "\n",
    "# Evaluate each model and compare predictive power\n",
    "comparison_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds, r2_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds, r2_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Compute comparison metrics\n",
    "    mae_mean_basketball = np.mean(mae_basketball_folds)\n",
    "    mae_mean_full = np.mean(mae_full_folds)\n",
    "    mae_diff = mae_mean_basketball - mae_mean_full  # Positive if Non-Basketball is better\n",
    "    mae_percent_improvement = (mae_diff / mae_mean_basketball * 100) if mae_mean_basketball != 0 else 0\n",
    "    folds_improved = sum(np.array(mae_full_folds) < np.array(mae_basketball_folds))\n",
    "    \n",
    "    r2_mean_basketball = np.mean(r2_basketball_folds)\n",
    "    r2_mean_full = np.mean(r2_full_folds)\n",
    "    r2_diff = r2_mean_full - r2_mean_basketball  # Positive if Non-Basketball is better\n",
    "    \n",
    "    # Diagnostics\n",
    "    print(f\"\\nDiagnostics for {name}:\")\n",
    "    print(f\"Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_basketball_folds]}\")\n",
    "    print(f\"Non-Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_full_folds]}\")\n",
    "    print(f\"MAE Differences (Basketball - Non-Basketball): {[f'{diff:.2f}' for diff in (np.array(mae_basketball_folds) - np.array(mae_full_folds))]}\")\n",
    "    print(f\"Basketball Features R2 Folds: {[f'{r2:.4f}' for r2 in r2_basketball_folds]}\")\n",
    "    print(f\"Non-Basketball Features R2 Folds: {[f'{r2:.4f}' for r2 in r2_full_folds]}\")\n",
    "    \n",
    "    # Store comparison results\n",
    "    comparison_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': mae_mean_basketball / mae_scale,\n",
    "        'MAE Mean (Non-Basketball Features)': mae_mean_full / mae_scale,\n",
    "        'MAE Difference': mae_diff / mae_scale,\n",
    "        'MAE % Improvement': mae_percent_improvement,\n",
    "        'Folds Improved (MAE)': folds_improved,\n",
    "        'R2 Mean (Basketball Features)': r2_mean_basketball,\n",
    "        'R2 Mean (Non-Basketball Features)': r2_mean_full,\n",
    "        'R2 Difference': r2_diff,\n",
    "        'Improved Predictive Power': 'Yes' if mae_diff > 0 else 'No'  # Based on MAE\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Mean', 'CV R2 Mean']])\n",
    "\n",
    "print(\"\\nPredictive Power Comparison:\")\n",
    "print(comparison_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                    'MAE Difference', 'MAE % Improvement', 'Folds Improved (MAE)', \n",
    "                    'R2 Mean (Basketball Features)', 'R2 Mean (Non-Basketball Features)', \n",
    "                    'R2 Difference', 'Improved Predictive Power']])\n",
    "\n",
    "# Highlight models with improved predictive power\n",
    "print(\"\\nModels with Improved Predictive Power (Lower MAE):\")\n",
    "improved_models = comparison_df[comparison_df['Improved Predictive Power'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Difference', 'MAE % Improvement', 'Folds Improved (MAE)']])\n",
    "else:\n",
    "    print(\"No models showed improved predictive power.\")\n",
    "\n",
    "# Target variable diagnostics\n",
    "print(\"\\nTarget Variable Diagnostics:\")\n",
    "print(\"y_train stats:\", y_train.describe())\n",
    "print(\"y_test stats:\", y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6bd97e36-5ab1-4d1a-ac80-3a1286278641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE Mean (Basketball Features)</th>\n",
       "      <th>MAE Mean (Non-Basketball Features)</th>\n",
       "      <th>MAE Difference</th>\n",
       "      <th>MAE % Improvement</th>\n",
       "      <th>Folds Improved (MAE)</th>\n",
       "      <th>R2 Mean (Basketball Features)</th>\n",
       "      <th>R2 Mean (Non-Basketball Features)</th>\n",
       "      <th>R2 Difference</th>\n",
       "      <th>Improved Predictive Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.0815</td>\n",
       "      <td>3.9082</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>4.2456</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>3.9083</td>\n",
       "      <td>3.6661</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>6.1972</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>4.0638</td>\n",
       "      <td>3.8971</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>4.1031</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>3.8626</td>\n",
       "      <td>3.8181</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>1.1526</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.1292</td>\n",
       "      <td>2.9776</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>4.8435</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3.1217</td>\n",
       "      <td>2.8546</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>8.5577</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.7736</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3.3178</td>\n",
       "      <td>3.2601</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>1.7371</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  MAE Mean (Basketball Features)  \\\n",
       "0  Linear Regression                          4.0815   \n",
       "1   Ridge Regression                          3.9083   \n",
       "2   Lasso Regression                          4.0638   \n",
       "3      Decision Tree                          3.8626   \n",
       "4      Random Forest                          3.1292   \n",
       "5            XGBoost                          3.1217   \n",
       "6                MLP                          3.3178   \n",
       "\n",
       "   MAE Mean (Non-Basketball Features)  MAE Difference  MAE % Improvement  \\\n",
       "0                              3.9082          0.1733             4.2456   \n",
       "1                              3.6661          0.2422             6.1972   \n",
       "2                              3.8971          0.1667             4.1031   \n",
       "3                              3.8181          0.0445             1.1526   \n",
       "4                              2.9776          0.1516             4.8435   \n",
       "5                              2.8546          0.2671             8.5577   \n",
       "6                              3.2601          0.0576             1.7371   \n",
       "\n",
       "   Folds Improved (MAE)  R2 Mean (Basketball Features)  \\\n",
       "0                     5                         0.6521   \n",
       "1                     5                         0.6952   \n",
       "2                     5                         0.6555   \n",
       "3                     4                         0.5837   \n",
       "4                     5                         0.7547   \n",
       "5                     4                         0.7477   \n",
       "6                     3                         0.7211   \n",
       "\n",
       "   R2 Mean (Non-Basketball Features)  R2 Difference Improved Predictive Power  \n",
       "0                             0.6773         0.0252                       Yes  \n",
       "1                             0.7223         0.0271                       Yes  \n",
       "2                             0.6775         0.0221                       Yes  \n",
       "3                             0.6418         0.0580                       Yes  \n",
       "4                             0.7787         0.0241                       Yes  \n",
       "5                             0.7736         0.0259                       Yes  \n",
       "6                             0.7294         0.0083                       Yes  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5e4e417f-7b81-4c3a-91a5-1e13854ab3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Linear Regression:\n",
      "Basketball Features MAE Folds: ['3740826.65', '4525841.75', '4544173.33', '4024244.54', '3572494.00']\n",
      "Non-Basketball Features MAE Folds: ['3691936.13', '4462166.10', '4265792.70', '3572444.79', '3548826.38']\n",
      "Differences (Basketball - Non-Basketball): ['48890.52', '63675.65', '278380.63', '451799.76', '23667.62']\n",
      "Differences Mean: 173282.83, Std: 186070.63\n",
      "\n",
      "Diagnostics for Ridge Regression:\n",
      "Basketball Features MAE Folds: ['3856472.20', '4296475.84', '4254339.11', '3541549.24', '3592792.25']\n",
      "Non-Basketball Features MAE Folds: ['3834568.80', '4083235.10', '3806456.98', '3099056.81', '3507285.88']\n",
      "Differences (Basketball - Non-Basketball): ['21903.40', '213240.73', '447882.14', '442492.43', '85506.37']\n",
      "Differences Mean: 242205.01, Std: 197702.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.378e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+15, tolerance: 3.638e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 2.844e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+15, tolerance: 2.951e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+15, tolerance: 2.854e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+15, tolerance: 3.087e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+15, tolerance: 2.815e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for Lasso Regression:\n",
      "Basketball Features MAE Folds: ['3761498.78', '4568600.45', '4476517.21', '3947381.21', '3565040.63']\n",
      "Non-Basketball Features MAE Folds: ['3708721.84', '4512573.12', '4257993.62', '3495448.90', '3510581.45']\n",
      "Differences (Basketball - Non-Basketball): ['52776.94', '56027.33', '218523.60', '451932.31', '54459.17']\n",
      "Differences Mean: 166743.87, Std: 174548.03\n",
      "\n",
      "Diagnostics for Decision Tree:\n",
      "Basketball Features MAE Folds: ['4020540.05', '4178112.64', '4118793.58', '4463997.06', '2531474.55']\n",
      "Non-Basketball Features MAE Folds: ['3601064.04', '3671415.94', '3790473.79', '3752321.18', '4275046.69']\n",
      "Differences (Basketball - Non-Basketball): ['419476.01', '506696.70', '328319.79', '711675.88', '-1743572.13']\n",
      "Differences Mean: 44519.25, Std: 1009593.00\n",
      "\n",
      "Diagnostics for Random Forest:\n",
      "Basketball Features MAE Folds: ['2908631.74', '3345985.65', '3382798.98', '3320501.60', '2688053.71']\n",
      "Non-Basketball Features MAE Folds: ['2734816.92', '3130814.25', '3286862.53', '3125710.51', '2609950.80']\n",
      "Differences (Basketball - Non-Basketball): ['173814.81', '215171.40', '95936.46', '194791.09', '78102.91']\n",
      "Differences Mean: 151563.33, Std: 61033.88\n",
      "\n",
      "Diagnostics for XGBoost:\n",
      "Basketball Features MAE Folds: ['3112488.10', '3130537.01', '3507065.07', '3287862.08', '2570683.05']\n",
      "Non-Basketball Features MAE Folds: ['2698542.75', '2628868.63', '3238603.23', '3021254.60', '2685629.41']\n",
      "Differences (Basketball - Non-Basketball): ['413945.35', '501668.39', '268461.84', '266607.48', '-114946.37']\n",
      "Differences Mean: 267147.34, Std: 235874.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnostics for MLP:\n",
      "Basketball Features MAE Folds: ['2970660.53', '3724806.65', '3441613.73', '3450227.44', '3001593.94']\n",
      "Non-Basketball Features MAE Folds: ['3214596.68', '3861375.86', '3155835.07', '3183242.95', '2885678.00']\n",
      "Differences (Basketball - Non-Basketball): ['-243936.15', '-136569.21', '285778.66', '266984.49', '115915.94']\n",
      "Differences Mean: 57634.75, Std: 238712.08\n",
      "\n",
      "Model Evaluation Results:\n",
      "                Model              Feature Set Dataset    MAE     R2  \\\n",
      "0   Linear Regression      Basketball Features    Test 4.2103 0.6694   \n",
      "1   Linear Regression  Non-Basketball Features    Test 3.7227 0.7482   \n",
      "2    Ridge Regression      Basketball Features    Test 4.1973 0.6927   \n",
      "3    Ridge Regression  Non-Basketball Features    Test 3.7478 0.7522   \n",
      "4    Lasso Regression      Basketball Features    Test 4.1848 0.6737   \n",
      "5    Lasso Regression  Non-Basketball Features    Test 3.6848 0.7499   \n",
      "6       Decision Tree      Basketball Features    Test 3.6175 0.6441   \n",
      "7       Decision Tree  Non-Basketball Features    Test 3.2624 0.7485   \n",
      "8       Random Forest      Basketball Features    Test 3.2911 0.7580   \n",
      "9       Random Forest  Non-Basketball Features    Test 2.9655 0.8089   \n",
      "10            XGBoost      Basketball Features    Test 3.4936 0.7049   \n",
      "11            XGBoost  Non-Basketball Features    Test 2.9324 0.8174   \n",
      "12                MLP      Basketball Features    Test 3.4367 0.7232   \n",
      "13                MLP  Non-Basketball Features    Test 3.3801 0.7316   \n",
      "\n",
      "    CV MAE Mean  \n",
      "0        4.0815  \n",
      "1        3.9082  \n",
      "2        3.9083  \n",
      "3        3.6661  \n",
      "4        4.0638  \n",
      "5        3.8971  \n",
      "6        3.8626  \n",
      "7        3.8181  \n",
      "8        3.1292  \n",
      "9        2.9776  \n",
      "10       3.1217  \n",
      "11       2.8546  \n",
      "12       3.3178  \n",
      "13       3.2601  \n",
      "\n",
      "Paired t-test Results for MAE:\n",
      "               Model  MAE Mean (Basketball Features)  \\\n",
      "0  Linear Regression                          4.0815   \n",
      "1   Ridge Regression                          3.9083   \n",
      "2   Lasso Regression                          4.0638   \n",
      "3      Decision Tree                          3.8626   \n",
      "4      Random Forest                          3.1292   \n",
      "5            XGBoost                          3.1217   \n",
      "6                MLP                          3.3178   \n",
      "\n",
      "   MAE Mean (Non-Basketball Features)  \\\n",
      "0                              3.9082   \n",
      "1                              3.6661   \n",
      "2                              3.8971   \n",
      "3                              3.8181   \n",
      "4                              2.9776   \n",
      "5                              2.8546   \n",
      "6                              3.2601   \n",
      "\n",
      "   MAE Difference (Basketball - Non-Basketball)  t-test Statistic  \\\n",
      "0                                        0.1733            2.0824   \n",
      "1                                        0.2422            2.7394   \n",
      "2                                        0.1667            2.1361   \n",
      "3                                        0.0445            0.0986   \n",
      "4                                        0.1516            5.5528   \n",
      "5                                        0.2671            2.5325   \n",
      "6                                        0.0576            0.5399   \n",
      "\n",
      "   t-test p-value MAE Improved  \n",
      "0          0.0529           No  \n",
      "1          0.0260          Yes  \n",
      "2          0.0498          Yes  \n",
      "3          0.4631           No  \n",
      "4          0.0026          Yes  \n",
      "5          0.0322          Yes  \n",
      "6          0.3090           No  \n",
      "\n",
      "Models with Significant MAE Improvements (p < 0.05):\n",
      "              Model  MAE Difference (Basketball - Non-Basketball)  \\\n",
      "1  Ridge Regression                                        0.2422   \n",
      "2  Lasso Regression                                        0.1667   \n",
      "4     Random Forest                                        0.1516   \n",
      "5           XGBoost                                        0.2671   \n",
      "\n",
      "   t-test p-value  \n",
      "1          0.0260  \n",
      "2          0.0498  \n",
      "4          0.0026  \n",
      "5          0.0322  \n",
      "\n",
      "Target Variable Diagnostics:\n",
      "y_train stats:              Salary\n",
      "count      354.0000\n",
      "mean   8415441.3588\n",
      "std   10152411.9406\n",
      "min      19186.0000\n",
      "25%    1782621.0000\n",
      "50%    4000000.0000\n",
      "75%   11539524.5000\n",
      "max   45780966.0000\n",
      "y_test stats:              Salary\n",
      "count       89.0000\n",
      "mean   8018585.4045\n",
      "std    9985556.7713\n",
      "min      85578.0000\n",
      "25%    1701593.0000\n",
      "50%    3300000.0000\n",
      "75%   10500000.0000\n",
      "max   44211146.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilfalk/Library/Python/3.12/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import ttest_rel\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define models with their best hyperparameters\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Linear Regression',\n",
    "        'model_basketball': LinearRegression(),\n",
    "        'model_full': LinearRegression()\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ridge Regression',\n",
    "        'model_basketball': Ridge(alpha=100.0),\n",
    "        'model_full': Ridge(alpha=100.0)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lasso Regression',\n",
    "        'model_basketball': Lasso(alpha=100.0, random_state=42),\n",
    "        'model_full': Lasso(alpha=100.0, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model_basketball': DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42),\n",
    "        'model_full': DecisionTreeRegressor(max_depth=3, min_samples_split=10, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model_basketball': RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "        'model_full': RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model_basketball': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=100, random_state=42),\n",
    "        'model_full': XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model_basketball': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000),\n",
    "        'model_full': MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, random_state=42, max_iter=1000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Number of cross-validation folds\n",
    "cv_folds = 5  # Set to 10 for more power if desired\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "results = []\n",
    "alpha = 0.05  # Significance level\n",
    "mae_scale = 1_000_000  # Scale MAE for display\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set, model_name):\n",
    "    # Test set evaluation\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation MAE scores\n",
    "    mae_folds = []\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_train_fold = y_train.iloc[train_idx] if isinstance(y_train, pd.DataFrame) else y_train[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx] if isinstance(y_train, pd.DataFrame) else y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold.values.ravel() if isinstance(y_train_fold, pd.DataFrame) else y_train_fold)\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        mae_folds.append(mean_absolute_error(y_val_fold, y_pred_fold))\n",
    "    \n",
    "    # Store results (scale MAE for display)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Feature Set': feature_set,\n",
    "        'Dataset': 'Test',\n",
    "        'MAE': test_mae / mae_scale,\n",
    "        'R2': test_r2,\n",
    "        'CV MAE Folds': mae_folds,  # Raw values for t-test\n",
    "        'CV MAE Mean': np.mean(mae_folds) / mae_scale\n",
    "    })\n",
    "    \n",
    "    return model, mae_folds\n",
    "\n",
    "# Evaluate each model and perform paired t-test\n",
    "ttest_results = []\n",
    "for model_info in models:\n",
    "    name = model_info['name']\n",
    "    model_basketball = model_info['model_basketball']\n",
    "    model_full = model_info['model_full']\n",
    "    \n",
    "    # Evaluate Basketball Features\n",
    "    _, mae_basketball_folds = evaluate_model(\n",
    "        model_basketball, \n",
    "        X_train_basketball_scaled, \n",
    "        X_test_basketball_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Evaluate Non-Basketball Features\n",
    "    _, mae_full_folds = evaluate_model(\n",
    "        model_full, \n",
    "        X_train_scaled, \n",
    "        X_test_scaled, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        'Non-Basketball Features', \n",
    "        name\n",
    "    )\n",
    "    \n",
    "    # Diagnostics: Print MAE scores and differences\n",
    "    print(f\"\\nDiagnostics for {name}:\")\n",
    "    print(f\"Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_basketball_folds]}\")\n",
    "    print(f\"Non-Basketball Features MAE Folds: {[f'{mae:.2f}' for mae in mae_full_folds]}\")\n",
    "    differences = np.array(mae_basketball_folds) - np.array(mae_full_folds)\n",
    "    print(f\"Differences (Basketball - Non-Basketball): {[f'{diff:.2f}' for diff in differences]}\")\n",
    "    print(f\"Differences Mean: {np.mean(differences):.2f}, Std: {np.std(differences, ddof=1):.2f}\")\n",
    "    \n",
    "    # Paired t-test (one-sided: test if Basketball MAE > Non-Basketball MAE)\n",
    "    stat_t, p_value_t = ttest_rel(mae_basketball_folds, mae_full_folds, alternative='greater')\n",
    "    mae_improved = p_value_t < alpha and np.mean(mae_full_folds) < np.mean(mae_basketball_folds)\n",
    "    \n",
    "    # Store t-test results\n",
    "    ttest_results.append({\n",
    "        'Model': name,\n",
    "        'MAE Mean (Basketball Features)': np.mean(mae_basketball_folds) / mae_scale,\n",
    "        'MAE Mean (Non-Basketball Features)': np.mean(mae_full_folds) / mae_scale,\n",
    "        'MAE Difference (Basketball - Non-Basketball)': (np.mean(mae_basketball_folds) - np.mean(mae_full_folds)) / mae_scale,\n",
    "        't-test Statistic': stat_t,\n",
    "        't-test p-value': p_value_t,\n",
    "        'MAE Improved': 'Yes' if mae_improved else 'No'\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "ttest_df = pd.DataFrame(ttest_results)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df[['Model', 'Feature Set', 'Dataset', 'MAE', 'R2', 'CV MAE Mean']])\n",
    "\n",
    "print(\"\\nPaired t-test Results for MAE:\")\n",
    "print(ttest_df[['Model', 'MAE Mean (Basketball Features)', 'MAE Mean (Non-Basketball Features)', \n",
    "                'MAE Difference (Basketball - Non-Basketball)', 't-test Statistic', \n",
    "                't-test p-value', 'MAE Improved']])\n",
    "\n",
    "# Highlight models with significant improvements\n",
    "print(\"\\nModels with Significant MAE Improvements (p < 0.05):\")\n",
    "improved_models = ttest_df[ttest_df['MAE Improved'] == 'Yes']\n",
    "if not improved_models.empty:\n",
    "    print(improved_models[['Model', 'MAE Difference (Basketball - Non-Basketball)', 't-test p-value']])\n",
    "else:\n",
    "    print(\"No models showed significant MAE improvements.\")\n",
    "\n",
    "# Target variable diagnostics\n",
    "print(\"\\nTarget Variable Diagnostics:\")\n",
    "print(\"y_train stats:\", y_train.describe())\n",
    "print(\"y_test stats:\", y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f3bdb7bf-f4d2-420b-8603-adace48bdaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE Mean (Basketball Features)</th>\n",
       "      <th>MAE Mean (Non-Basketball Features)</th>\n",
       "      <th>MAE Difference (Basketball - Non-Basketball)</th>\n",
       "      <th>t-test Statistic</th>\n",
       "      <th>t-test p-value</th>\n",
       "      <th>MAE Improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.0815</td>\n",
       "      <td>3.9082</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>2.0824</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>3.9083</td>\n",
       "      <td>3.6661</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>2.7394</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>4.0638</td>\n",
       "      <td>3.8971</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>2.1361</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>3.8626</td>\n",
       "      <td>3.8181</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.1292</td>\n",
       "      <td>2.9776</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>5.5528</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3.1217</td>\n",
       "      <td>2.8546</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>2.5325</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3.3178</td>\n",
       "      <td>3.2601</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  MAE Mean (Basketball Features)  \\\n",
       "0  Linear Regression                          4.0815   \n",
       "1   Ridge Regression                          3.9083   \n",
       "2   Lasso Regression                          4.0638   \n",
       "3      Decision Tree                          3.8626   \n",
       "4      Random Forest                          3.1292   \n",
       "5            XGBoost                          3.1217   \n",
       "6                MLP                          3.3178   \n",
       "\n",
       "   MAE Mean (Non-Basketball Features)  \\\n",
       "0                              3.9082   \n",
       "1                              3.6661   \n",
       "2                              3.8971   \n",
       "3                              3.8181   \n",
       "4                              2.9776   \n",
       "5                              2.8546   \n",
       "6                              3.2601   \n",
       "\n",
       "   MAE Difference (Basketball - Non-Basketball)  t-test Statistic  \\\n",
       "0                                        0.1733            2.0824   \n",
       "1                                        0.2422            2.7394   \n",
       "2                                        0.1667            2.1361   \n",
       "3                                        0.0445            0.0986   \n",
       "4                                        0.1516            5.5528   \n",
       "5                                        0.2671            2.5325   \n",
       "6                                        0.0576            0.5399   \n",
       "\n",
       "   t-test p-value MAE Improved  \n",
       "0          0.0529           No  \n",
       "1          0.0260          Yes  \n",
       "2          0.0498          Yes  \n",
       "3          0.4631           No  \n",
       "4          0.0026          Yes  \n",
       "5          0.0322          Yes  \n",
       "6          0.3090           No  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3623cd78-286b-4bfa-970c-865f62687f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>CV MAE Folds</th>\n",
       "      <th>CV MAE Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>4.2103</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>[3740826.6544753066, 4525841.746212794, 454417...</td>\n",
       "      <td>4.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.7227</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>[3691936.1307729594, 4462166.098131463, 426579...</td>\n",
       "      <td>3.9082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>4.1973</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>[3856472.1997101484, 4296475.835153485, 425433...</td>\n",
       "      <td>3.9083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.7478</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>[3834568.801955731, 4083235.10228124, 3806456....</td>\n",
       "      <td>3.6661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>4.1848</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>[3761498.77580069, 4568600.4538105875, 4476517...</td>\n",
       "      <td>4.0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.6848</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>[3708721.8400306096, 4512573.124213011, 425799...</td>\n",
       "      <td>3.8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.6175</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>[4020540.0549034243, 4178112.6380699496, 41187...</td>\n",
       "      <td>3.8626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.2624</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>[3601064.0422656345, 3671415.9400215405, 37904...</td>\n",
       "      <td>3.8181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.2911</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>[2908631.7374258246, 3345985.6508251196, 33827...</td>\n",
       "      <td>3.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>2.9655</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>[2734816.9234012156, 3130814.25209741, 3286862...</td>\n",
       "      <td>2.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.4936</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>[3112488.0994718308, 3130537.014524648, 350706...</td>\n",
       "      <td>3.1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>2.9324</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>[2698542.7502200706, 2628868.6285211267, 32386...</td>\n",
       "      <td>2.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.4367</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>[2970660.531245668, 3724806.6502319383, 344161...</td>\n",
       "      <td>3.3178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Non-Basketball Features</td>\n",
       "      <td>Test</td>\n",
       "      <td>3.3801</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>[3214596.677037668, 3861375.8586355415, 315583...</td>\n",
       "      <td>3.2601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model              Feature Set Dataset    MAE     R2  \\\n",
       "0   Linear Regression      Basketball Features    Test 4.2103 0.6694   \n",
       "1   Linear Regression  Non-Basketball Features    Test 3.7227 0.7482   \n",
       "2    Ridge Regression      Basketball Features    Test 4.1973 0.6927   \n",
       "3    Ridge Regression  Non-Basketball Features    Test 3.7478 0.7522   \n",
       "4    Lasso Regression      Basketball Features    Test 4.1848 0.6737   \n",
       "5    Lasso Regression  Non-Basketball Features    Test 3.6848 0.7499   \n",
       "6       Decision Tree      Basketball Features    Test 3.6175 0.6441   \n",
       "7       Decision Tree  Non-Basketball Features    Test 3.2624 0.7485   \n",
       "8       Random Forest      Basketball Features    Test 3.2911 0.7580   \n",
       "9       Random Forest  Non-Basketball Features    Test 2.9655 0.8089   \n",
       "10            XGBoost      Basketball Features    Test 3.4936 0.7049   \n",
       "11            XGBoost  Non-Basketball Features    Test 2.9324 0.8174   \n",
       "12                MLP      Basketball Features    Test 3.4367 0.7232   \n",
       "13                MLP  Non-Basketball Features    Test 3.3801 0.7316   \n",
       "\n",
       "                                         CV MAE Folds  CV MAE Mean  \n",
       "0   [3740826.6544753066, 4525841.746212794, 454417...       4.0815  \n",
       "1   [3691936.1307729594, 4462166.098131463, 426579...       3.9082  \n",
       "2   [3856472.1997101484, 4296475.835153485, 425433...       3.9083  \n",
       "3   [3834568.801955731, 4083235.10228124, 3806456....       3.6661  \n",
       "4   [3761498.77580069, 4568600.4538105875, 4476517...       4.0638  \n",
       "5   [3708721.8400306096, 4512573.124213011, 425799...       3.8971  \n",
       "6   [4020540.0549034243, 4178112.6380699496, 41187...       3.8626  \n",
       "7   [3601064.0422656345, 3671415.9400215405, 37904...       3.8181  \n",
       "8   [2908631.7374258246, 3345985.6508251196, 33827...       3.1292  \n",
       "9   [2734816.9234012156, 3130814.25209741, 3286862...       2.9776  \n",
       "10  [3112488.0994718308, 3130537.014524648, 350706...       3.1217  \n",
       "11  [2698542.7502200706, 2628868.6285211267, 32386...       2.8546  \n",
       "12  [2970660.531245668, 3724806.6502319383, 344161...       3.3178  \n",
       "13  [3214596.677037668, 3861375.8586355415, 315583...       3.2601  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "877abf1c-af04-4a98-8dd5-bb04947ea606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns (35): ['Team', 'years_with_team', 'draft_pos', 'all_star', 'num_teams', 'Age', 'GP', 'W', 'L', 'Min', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'PF', 'FP', 'DD2', 'TD3', '+/-', 'ig_followers', 'resigned', 'Agent']\n",
      "Feature columns for SHAP (34): ['years_with_team', 'draft_pos', 'all_star', 'num_teams', 'Age', 'GP', 'W', 'L', 'Min', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK', 'PF', 'FP', 'DD2', 'TD3', '+/-', 'ig_followers', 'resigned', 'Agent']\n",
      "X_train_scaled shape: (354, 35)\n",
      "X_test_scaled shape: (89, 35)\n"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 12,\n",
    "    'font.family': 'Arial'\n",
    "})\n",
    "\n",
    "# Define feature columns from X_train (including all features, possibly including 'Team')\n",
    "all_columns = list(X_train.columns)\n",
    "print(f\"All columns ({len(all_columns)}): {all_columns}\")\n",
    "\n",
    "# Define feature columns for SHAP visualization (excluding 'Team' for interpretability)\n",
    "feature_columns = [col for col in X_train.columns if col != 'Team']\n",
    "print(f\"Feature columns for SHAP ({len(feature_columns)}): {feature_columns}\")\n",
    "\n",
    "# Verify shapes of scaled data\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# Check if the model expects the same number of features\n",
    "if X_train_scaled.shape[1] != xgb_full.get_booster().num_features():\n",
    "    raise ValueError(f\"Feature mismatch: Model expects {xgb_full.get_booster().num_features()} features, but X_train_scaled has {X_train_scaled.shape[1]}\")\n",
    "\n",
    "# Convert scaled arrays to DataFrames with all columns\n",
    "X_train_features_df = pd.DataFrame(X_train_scaled, columns=all_columns)\n",
    "X_test_features_df = pd.DataFrame(X_test_scaled, columns=all_columns)\n",
    "\n",
    "# Define team groups\n",
    "group1_teams = [19, 0, 15, 6, 9]\n",
    "group2_teams = [28, 7, 17, 21, 29]\n",
    "\n",
    "def compute_shap_for_group(group_teams, group_name, X_test, X_test_scaled, all_columns, feature_columns, model):\n",
    "    # Filter X_test (unscaled DataFrame) for the specified teams\n",
    "    group_data = X_test[X_test['Team'].isin(group_teams)]\n",
    "    \n",
    "    if group_data.empty:\n",
    "        print(f\"No data found for {group_name} teams: {group_teams}\")\n",
    "        return\n",
    "    \n",
    "    # Get the indices of the filtered teams\n",
    "    group_indices = group_data.index\n",
    "    \n",
    "    # Use the corresponding scaled features from X_test_scaled (all 28 features)\n",
    "    group_data_features = pd.DataFrame(X_test_scaled[group_indices], columns=all_columns)\n",
    "    \n",
    "    # Get predictions for the group\n",
    "    group_predictions = model.predict(group_data_features)\n",
    "    \n",
    "    # Initialize SHAP explainer for XGBoost\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(group_data_features)\n",
    "    \n",
    "    # Compute mean absolute SHAP values for the bar plot (exclude 'Team' for visualization)\n",
    "    team_idx = all_columns.index('Team') if 'Team' in all_columns else None\n",
    "    if team_idx is not None:\n",
    "        # Exclude 'Team' from SHAP values and features for plotting\n",
    "        plot_shap_values = np.delete(shap_values, team_idx, axis=1)\n",
    "        plot_features = feature_columns\n",
    "    else:\n",
    "        plot_shap_values = shap_values\n",
    "        plot_features = all_columns\n",
    "    \n",
    "    mean_shap_values = np.abs(plot_shap_values).mean(axis=0)\n",
    "    \n",
    "    # Sort features by importance (descending)\n",
    "    sorted_idx = np.argsort(-mean_shap_values)\n",
    "    sorted_features = np.array(plot_features)[sorted_idx]\n",
    "    sorted_values = mean_shap_values[sorted_idx]\n",
    "    \n",
    "    # Generate the SHAP bar plot\n",
    "    plt.figure(figsize=(10, len(plot_features) * 0.5))\n",
    "    shap.summary_plot(plot_shap_values, group_data_features[plot_features], plot_type=\"bar\", show=False, \n",
    "                      color='#4C78A8', max_display=len(plot_features))\n",
    "    plt.title(f\"SHAP Feature Importance for {group_name}\", pad=20)\n",
    "    plt.xlabel(\"Mean |SHAP Value| (Average Impact on Model Output)\", fontsize=14)\n",
    "    \n",
    "    # Access the bars in the plot\n",
    "    ax = plt.gca()\n",
    "    bars = [child for child in ax.get_children() if isinstance(child, plt.Rectangle) and child.get_height() > 0]\n",
    "    bars = sorted(bars, key=lambda b: b.get_y(), reverse=True)\n",
    "    \n",
    "    # Add values next to the bars\n",
    "    max_value = max(sorted_values)\n",
    "    for bar, value in zip(bars, sorted_values):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.05 * max_value, bar.get_y() + bar.get_height()/2, f'{value:.2f}', \n",
    "                 ha='left', va='center', fontsize=10, color='black')\n",
    "    \n",
    "    # Adjust x-axis limits\n",
    "    plt.xlim(0, max_value * 1.3)\n",
    "    \n",
    "    # Add gridlines\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'shap_experiment_3_{group_name.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Compute SHAP values and plot for Group 1\n",
    "compute_shap_for_group(group1_teams, \"Group 1\", X_test, X_test_scaled, all_columns, feature_columns, xgb_full)\n",
    "\n",
    "# Compute SHAP values and plot for Group 2\n",
    "compute_shap_for_group(group2_teams, \"Group 2\", X_test, X_test_scaled, all_columns, feature_columns, xgb_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e0dab-177a-42e9-8b5b-718102f56a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
